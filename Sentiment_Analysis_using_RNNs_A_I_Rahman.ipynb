{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Senay-37/InstiSocial/blob/main/Sentiment_Analysis_using_RNNs_A_I_Rahman.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RNNs for Text Classification\n",
        "\n",
        "We will use a RNN based model to perform classification of SMS messages into Spam or not Spam. The notebook has split the entire process into several parts for your convienience. To appreciate preprocessing in music, it is important to understand preprocessing in other domains. You may need to read up upon tokenization, embeddings (Glove) and Dataloaders, as well as how to pipeline an end - to - end AI model\n",
        "\n",
        "**Resources:** \\\n",
        "https://www.geeksforgeeks.org/pre-trained-word-embedding-using-glove-in-nlp-models/\n",
        "\n",
        "We do not expect you to finish the code entirely, take help whenever required, but understand the code you have written, do not blindly copy code. In case of help required at any time, feel free to contact the project leads.\n",
        "\n",
        "| Name | Phone Number |\n",
        "| :-- | :-- |\n",
        "| Pranay Mathur | 7032832559|\n",
        "| Swathi Narashiman | 6379869509 |"
      ],
      "metadata": {
        "id": "42xt85VTJ_ev"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RwYp_PIQjQxv"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "from IPython.display import clear_output\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import spacy\n",
        "import re\n",
        "import string\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import tqdm\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Downloading the Spam SMS Dataset\n",
        "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/00228/smsspamcollection.zip\n",
        "\n",
        "!unzip /content/smsspamcollection.zip\n",
        "!rm /content/readme\n",
        "!rm !rm /content/smsspamcollection.zip\n",
        "\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "FBvZraf2jYIG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Downloading the GloVe embeddings database\n",
        "\n",
        "!wget https://nlp.stanford.edu/data/glove.6B.zip\n",
        "\n",
        "!unzip /content/glove.6B.zip\n",
        "\n",
        "!rm -rf /content/glove.6B.zip\n",
        "!rm /content/glove.6B.100d.txt\n",
        "!rm /content/glove.6B.200d.txt\n",
        "!rm /content/glove.6B.300d.txt\n",
        "\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "n1HceqWHjYKY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f800c62-ea1c-44d0-e705-97d379b00262"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-04-26 14:07:08--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "Unable to establish SSL connection.\n",
            "unzip:  cannot find or open /content/glove.6B.zip, /content/glove.6B.zip.zip or /content/glove.6B.zip.ZIP.\n",
            "rm: cannot remove '/content/glove.6B.100d.txt': No such file or directory\n",
            "rm: cannot remove '/content/glove.6B.200d.txt': No such file or directory\n",
            "rm: cannot remove '/content/glove.6B.300d.txt': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = []\n",
        "label = []\n",
        "\n",
        "with open(\"/content/SMSSpamCollection\") as f:\n",
        "\n",
        "    \"\"\" read each line of the text file and create a Pandas Data Frame\n",
        "        label spam messages as 1 and legit messages as 0\n",
        "    \"\"\"\n",
        "\n",
        "    ###########YOUR CODE HERE###########"
      ],
      "metadata": {
        "id": "JAdzZHGZl3C5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a Pandas Dataframe\n",
        "sms = pd.DataFrame(zip(text, label), columns = [\"Text\", \"Label\"])\n",
        "sms['Text_Length'] = ###########YOUR CODE HERE###########"
      ],
      "metadata": {
        "id": "SRuld-70mCdT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spacy_tokenizer = spacy.load('en_core_web_sm')\n",
        "def tokenize (text):\n",
        "\n",
        "    \"\"\"remove any non-ascii characters\n",
        "       remove punctuations\n",
        "       tokenize the text\n",
        "       return the tokenized text\n",
        "    \"\"\"\n",
        "\n",
        "    ###########YOUR CODE HERE###########"
      ],
      "metadata": {
        "id": "KzOJgFYCmTPx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize the text sms in the Pandas Dataframe\n",
        "sms[\"Tokenized_Text\"] = ###########YOUR CODE HERE###########"
      ],
      "metadata": {
        "id": "i5mH9RpmmsEl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_GloVe_embeddings(glove_file):\n",
        "\n",
        "    \"\"\"\n",
        "        load the GloVe embeddings from the files downloaded\n",
        "        create a dictionary of the form {word : word embedding}\n",
        "    \"\"\"\n",
        "\n",
        "    ###########YOUR CODE HERE###########"
      ],
      "metadata": {
        "id": "Vw0txfuIm29P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def embed_text(tokenized_text, word_embeddings, max_text_length=20, embedding_size = 50):\n",
        "    \"\"\"\n",
        "        given a sequence of tokens convert them to their word embeddings\n",
        "    \"\"\"\n",
        "\n",
        "    ###########YOUR CODE HERE###########"
      ],
      "metadata": {
        "id": "o-O4DeKRnjL8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sms[\"Embedded_Text\"] = ###########YOUR CODE HERE###########"
      ],
      "metadata": {
        "id": "MmOFLtqbn-2w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Complete the below code for the Dataloader class\"\"\"\n",
        "class load_dataset(Dataset):\n",
        "    def __init__(self, X, Y):\n",
        "        \"\"\"\n",
        "            X: the embeddings of the sentence\n",
        "            Y: ground truth of the sentence (0- positive, 1- negative)\n",
        "        \"\"\"\n",
        "        self.X = X\n",
        "        self.y = Y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.y)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        ###########YOUR CODE HERE###########"
      ],
      "metadata": {
        "id": "WtOWOOv_jYPF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self, vocab_size, num_layers):\n",
        "        \"\"\"Define your layers, activation functions here\"\"\"\n",
        "        ###########YOUR CODE HERE###########\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Perform a forward pass\"\"\"\n",
        "        ###########YOUR CODE HERE###########"
      ],
      "metadata": {
        "id": "q6fuH7svjYRr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(num_epochs, train_loader, model, criterion, optimizer):\n",
        "    \"\"\"\n",
        "    Write a trainer loop for the model. It must follow the below pattern\n",
        "    1. Pass the input to the model and perform forward propagation\n",
        "    2. Obtain losses\n",
        "    3. Backpropagate to find the gradients\n",
        "\n",
        "    Make sure to check the accuracy of the model at regular intervals\n",
        "    \"\"\"\n",
        "\n",
        "    ###########YOUR CODE HERE###########"
      ],
      "metadata": {
        "id": "rRlz7uqbjYUC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "1. Write code to split your available data into training and testing splits\n",
        "2. Define the model\n",
        "3. Set up hyper-parameters such as learning rate, number of epochs, batch size\n",
        "4. Train the model by using the function you defined above\n",
        "5. Check the model accuracy by running the model on the testing split\n",
        "6. Save the model as a .pth file\n",
        "\"\"\"\n",
        "\n",
        "###########YOUR CODE HERE###########"
      ],
      "metadata": {
        "id": "Rap_LDx1jYW4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}